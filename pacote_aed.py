# -*- coding: utf-8 -*-
"""Pacote_AED.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YtJz7xYpyzoQX56XTHtetbhwqnGnIYI-
"""

import pandas as pd
import seaborn as sns
sns.set_palette("deep")
import matplotlib.pyplot as plt
import math
import numpy as np
import statsmodels.api as sm
from scipy.stats import t
from scipy.stats import norm
from scipy.stats import ttest_ind
from scipy.stats import ttest_rel
from scipy.stats import bartlett
from scipy.stats import binom
from statsmodels.stats.proportion import proportions_ztest

#FUNÇÃO PARA REALIZAR A ANÁLISE UNIVARIADA
def univariada(coluna):
  """Está é um função para analisar uma variável por vez. 
A análise leverá em conta se a variável é nominal, ordinal, discreta ou contínua,
porém é necessário fazer o devido tratamento para que todas variáveis qualitativas
sejam do tipo 'object'
argumento1 > variável(coluna dataframe)
  """
  if coluna.dtype == 'object':
    #Tabela de frequencia
    tabela = coluna.value_counts().reset_index()
    nome_coluna = tabela.columns[1]
    tabela = tabela.rename(columns={nome_coluna: 'frequencia_absoluta'})
    tabela = tabela.rename(columns={'index': nome_coluna})
    tabela['frequencia_relativa'] = tabela['frequencia_absoluta']/tabela['frequencia_absoluta'].sum()
    tabela['frequencia_acumulada'] = tabela['frequencia_relativa'].cumsum()
    variavel = tabela.columns[0]
    print('TABELA DE FREQUÊNCIA')
    print(' ')
    print(tabela.to_string(index=False))
    print(' ')

    #verificando valores nulos/ausentes
    print(f'''CONTAGEM DE VALORES NULOS/AUSENTES
{len(coluna)-coluna.count()}''')
    print(' ')

    if len(coluna.value_counts()) > 3:
        print('GRÁFICO DE BARRAS')
        # Plotando gráficos de barra
        plt.figure(figsize=(5, 3))
        sns.barplot(x=tabela['frequencia_relativa'], y=tabela[variavel], edgecolor='black', palette='deep')
        plt.xlabel('frequencia_relativa')
        plt.ylabel(variavel)
        plt.tight_layout()
        plt.show()
    else:
        print('GRÁFICO DE PIZZA')
        # Definindo uma paleta de cores personalizada
        plt.figure(figsize=(3, 3))
        plt.pie(tabela['frequencia_relativa'], labels=tabela[variavel], autopct='%1.1f%%', startangle=140)
        plt.axis('equal')
        plt.show()
  else:
      # Analisando as medidas estatísticas
      print(f'''MEDIDAS ESTATÍSTICAS

{coluna.describe()}

CONTAGEM DE VALORES NULOS/AUSENTES
{len(coluna)-coluna.count()}''')
      print('')
      print('HISTOGRAMA E BOXPLOT')
      # Definindo a paleta de cores globalmente
      # Plotando histograma e boxplot
      num_bins = 1 + int(math.log2(len(coluna))) # Calculando o número de bins usando a regra de Sturges
      fig, axes = plt.subplots(1, 2, figsize=(6, 3))
      sns.histplot(x=coluna, bins=num_bins, kde=False, ax=axes[0])
      axes[0].set_ylabel('Frequência absoluta')
      axes[0].set_xlabel(coluna.name)
      sns.boxplot(y=coluna, ax=axes[1])
      axes[1].set_xlabel(coluna.name)
      axes[1].set_ylabel('')
      plt.tight_layout()
      plt.show()

#FUNÇÃO PARA REALIZAR A ANÁLISE BIVARIADA
def bivariada(explicativa, resposta, faixas=0):
  """Esta é uma função que analisa a correlação/associação entre uma variável explicativa e uma variável resposta.
A técnicas utilizadas são Person, IV e R², a depender dos tipos de variáveis.
argumento1 > variável explicativa(coluna dataframe).
argumento2 > variável resposta(coluna dataframe)(Se for binária precisa ser do tipo int e conter os valores 0/1).
argumento3 > número de faixas, caso necessário(int)."""

#Calculando a correlação de Person
  if len(explicativa.unique()) > 2 and explicativa.dtype != 'object' and len(resposta.unique()) > 2:
    #calculando a correlação
    correlacao = round(explicativa.corr(resposta), 2)
    #classificando
    benchmark = ''
    if correlacao <= -0.7:
      benchmark = 'FORTEMENTE NEGATIVA'
    elif correlacao <= 0.6:
      benchmark = 'FRACA'
    else:
      benchmark = 'FORTEMENTE POSITIVA'
    print(f"A CORRELAÇÃO DE PERSON É: {correlacao}")
    print(f'CLASSIFICAÇÃO: {benchmark}')
    print('')
    #Plotando o gráfico de dispersão
    cor_deep = sns.color_palette('deep')[0] 
    plt.figure(figsize=(4, 3))
    sns.scatterplot(x=explicativa, y=resposta, color=cor_deep)
    plt.xlabel(explicativa.name)
    plt.ylabel(resposta.name)
    plt.show()

#Calculando o information value
  elif len(resposta.unique()) == 2:
    #Criando faixas se a variável for numérica
    numerica = ''
    if type(explicativa) != str and explicativa.nunique() > 15:
      explicativa_num = explicativa #fazendo uma cópia da variável para o bloxplot
      if faixas != 0:
        explicativa = pd.cut(explicativa, bins=faixas)
        explicativa = explicativa.astype(str)
      else:
        faixas = 1 + int(math.log2(len(explicativa)))
        explicativa = pd.cut(explicativa, bins=faixas)
        explicativa = explicativa.astype(str)
      numerica = 'Sim'
  #Criando a tabela IV
    df_iv = pd.crosstab(explicativa, resposta)
    variavel_resposta = resposta.name
    df_iv['Freq_absoluta'] = df_iv[1] + df_iv[0]
    df_iv['Freq_relativa'] = df_iv['Freq_absoluta']/df_iv['Freq_absoluta'].sum()
    df_iv['Valor_Um_relativo'] = (df_iv[1]/df_iv[1].sum())
    df_iv['Valor_Zero_relativo'] = (df_iv[0]/df_iv[0].sum())
    df_iv['Taxa_Valor_Um'] = (df_iv[1]/df_iv['Freq_absoluta'])
    df_iv['Odds'] = df_iv['Valor_Um_relativo']/df_iv['Valor_Zero_relativo']
    df_iv['IV'] = (df_iv['Valor_Um_relativo']-df_iv['Valor_Zero_relativo'])* np.log(df_iv['Odds'])
    df_iv['IV'].replace(np.inf, 0, inplace=True)
    df_iv = df_iv.sort_values(by='Taxa_Valor_Um')
    df_iv = df_iv.drop(columns=['Freq_absoluta','Freq_relativa','Valor_Um_relativo','Valor_Zero_relativo'])
    soma_iv = round(df_iv['IV'].sum(), 2)
  #classificando
    benchmark = ''
    if soma_iv <= 0.02:
      benchmark = 'MUITO FRACO'
    elif soma_iv < 0.1:
      benchmark = 'FRACO'
    elif soma_iv < 0.3:
      benchmark = 'MÉDIO'
    elif soma_iv < 0.5:
      benchmark = 'FORTE'
    else:
      benchmark = 'MUITO FORTE'
    #organizando a tabela
    df_iv2 = df_iv.reset_index()
    #Printando a tabela IV e o resultado
    print('TABELA IV')
    print('')
    print(df_iv)
    print(f'''
O INFORMATION VALUE TOTAL É: {soma_iv}
CLASSIFICAÇÃO: {benchmark}''')
  #printando o gráfico
    print('')
    if numerica == 'Sim':
      plt.figure(figsize=(4, 3))
      sns.boxplot(x=resposta, y=explicativa_num, palette='deep')
      plt.xlabel(resposta.name)
      plt.ylabel(explicativa.name)
      plt.tight_layout()
      plt.show()
    elif numerica != 'Sim': 
      plt.figure(figsize=(5, 3))
      sns.barplot(x=df_iv2.iloc[:,3], y=df_iv2.iloc[:,0].astype(str), edgecolor='black', palette='deep')
      plt.xlabel('Taxa_Valor_Um')
      plt.ylabel(df_iv2.iloc[:,0].name)
      plt.tight_layout()
      plt.show()

#Calculando o coeficiente de determinação(R²)
  elif len(resposta.unique()) > 2 and ((len(explicativa.unique()) == 2 or explicativa.dtype == 'object')):
    #Codificando a variável qualitativa e calculando o R²
    df_reg = pd.get_dummies(explicativa, drop_first=True)
    variavel_dummie = sm.add_constant(df_reg)
    modelo = sm.OLS(resposta, variavel_dummie).fit() #Cria um modelo de regressão linear simples
    r_squared = round(modelo.rsquared, 2) #Extrai o R²
    #classificando
    benchmark = ''
    if r_squared <= 0.25:
      benchmark = 'FRACO'
    elif r_squared < 0.5:
      benchmark = 'MÉDIO'
    elif r_squared < 0.75:
      benchmark = 'FORTE'
    else:
      benchmark = 'MUITO FORTE'
  #Printando
    print(f'''O COEFICIENTE DE DETERMINAÇÃO(R²) É: {r_squared}
  CLASSIFICAÇÃO: {benchmark}''')
    print('')
    plt.figure(figsize=(len(explicativa.unique())+2, 3))
    sns.boxplot(x=explicativa, y=resposta, palette='deep')
    plt.xlabel(explicativa.name)
    plt.ylabel(resposta.name)
    plt.tight_layout()
    plt.show()
      
#FUNÇÃO PARA IDENTIFICAR OS ÍNDICES DOS OUTLIERS EM REFERÊNCIA A UMA VARIÁVEL RESPOSTA BINÁRIA
def outliers(explicativa, resposta):
    """Está é uma função que retorna os índices considerados outliers em relação a uma variável binária.
    É necessário atribuir o retorno a uma variável, para obter os ídices.
    argumento1 > variável explicativa(coluna dataframe).
    argumento2 > variável resposta(coluna dataframe)."""
    outliers_indices = []

    for classe in range(2): 
        explicativa_classe = explicativa[resposta == classe]
        Q1 = np.percentile(explicativa_classe, 25)
        Q3 = np.percentile(explicativa_classe, 75)
        IQR = Q3 - Q1
        limite_inferior = Q1 - 1.5 * IQR
        limite_superior = Q3 + 1.5 * IQR

        outliers_indices_classe = np.where((resposta == classe) & ((explicativa_classe < limite_inferior) | (explicativa_classe > limite_superior)))
        outliers_indices.extend(outliers_indices_classe[0])

    return outliers_indices

#FUNÇÃO PARA CONSTRUIR UM RANKING DE ASSOCIAÇÃO/CORRELAÇÃO ENTRE AS VARIÁVEIS EXPLICATIVAS E A VARIÁVEL RESPOSTA
def ranking(df, resposta, faixas=0):
  """Esta função retorna uma tabela com um ranking de associação/correlação.
  argumento1 > dataframe(variáveis explicativas)
  argumento2 > variável resposta(coluna dataframe)(Se for binária precisa ser do tipo int e conter os valores 0/1).
  argumento3 > faixas, caso necessário(int)."""
  #criando uma cópia do df para não alterar o original
  df_funcao = df.copy()
  #criando as listas para armazenar os resulados
  valor = []
  tecnica = []
  variavel = []
  classificacao = []
  #Iterando entre todas colunas e a variável resposta
  for explicativa in df_funcao.columns:
    #Calculando a correlação de Person
    if len(df_funcao[explicativa].unique()) > 2 and df_funcao[explicativa].dtype != 'object' and len(resposta.unique()) > 2:
      #calculando a correlação
      correlacao = round(df_funcao[explicativa].corr(resposta), 2)
      #classificando
      benchmark = ''
      if correlacao <= -0.7:
        benchmark = 'FORTE'
      elif correlacao <= 0.6:
        benchmark = 'FRACO'
      else:
        benchmark = 'FORTE'
      #armazenando o resultado
      variavel.append(explicativa)
      tecnica.append('Person')
      valor.append(correlacao)
      classificacao.append(benchmark)
    #Calculando o information value
    elif len(resposta.unique()) == 2:
      #Criando faixas se a variável for numérica
      numerica = ''
      if type(df_funcao[explicativa]) != str and df_funcao[explicativa].nunique() > 15:
        if faixas != 0:
          df_funcao[explicativa] = pd.cut(df_funcao[explicativa], bins=faixas)
          df_funcao[explicativa] = df_funcao[explicativa].astype(str)
        else:
          faixas = 1 + int(math.log2(len(df[explicativa])))
          df_funcao[explicativa] = pd.cut(df_funcao[explicativa], bins=faixas)
          df_funcao[explicativa] = df_funcao[explicativa].astype(str)
        numerica = 'Sim'
    #Criando a tabela IV
      df_iv = pd.crosstab(df_funcao[explicativa], resposta)
      variavel_resposta = resposta.name
      df_iv['Freq_absoluta'] = df_iv[1] + df_iv[0]
      df_iv['Freq_relativa'] = df_iv['Freq_absoluta']/df_iv['Freq_absoluta'].sum()
      df_iv['Valor_Um_relativo'] = (df_iv[1]/df_iv[1].sum())
      df_iv['Valor_Zero_relativo'] = (df_iv[0]/df_iv[0].sum())
      df_iv['Taxa_Valor_Um'] = (df_iv[1]/df_iv['Freq_absoluta'])
      df_iv['Odds'] = df_iv['Valor_Um_relativo']/df_iv['Valor_Zero_relativo']
      df_iv['IV'] = (df_iv['Valor_Um_relativo']-df_iv['Valor_Zero_relativo'])* np.log(df_iv['Odds'])
      df_iv['IV'].replace(np.inf, 0, inplace=True)
      df_iv = df_iv.sort_values(by='Taxa_Valor_Um')
      df_iv = df_iv.drop(columns=['Freq_absoluta','Freq_relativa','Valor_Um_relativo','Valor_Zero_relativo'])
      soma_iv = round(df_iv['IV'].sum(), 2)
    #classificando
      benchmark = ''
      if soma_iv <= 0.02:
        benchmark = 'MUITO FRACO'
      elif soma_iv < 0.1:
        benchmark = 'FRACO'
      elif soma_iv < 0.3:
        benchmark = 'MÉDIO'
      elif soma_iv < 0.5:
        benchmark = 'FORTE'
      else:
        benchmark = 'MUITO FORTE'
      #armazenando o resultado
      variavel.append(explicativa)
      tecnica.append('IV')
      valor.append(soma_iv)
      classificacao.append(benchmark)
    #Calculando o coeficiente de determinação(R²)
    elif len(resposta.unique()) > 2 and ((len(df_funcao[explicativa].unique()) == 2 or df_funcao[explicativa].dtype == 'object')):
      #Codificando a variável qualitativa e calculando o R²
      df_reg = pd.get_dummies(df_funcao[explicativa], drop_first=True)
      variavel_dummie = sm.add_constant(df_reg)
      modelo = sm.OLS(resposta, variavel_dummie).fit() #Cria um modelo de regressão linear simples
      r_squared = round(modelo.rsquared, 2) #Extrai o R²
      #classificando
      benchmark = ''
      if r_squared <= 0.25:
        benchmark = 'FRACO'
      elif r_squared < 0.5:
        benchmark = 'MÉDIO'
      elif r_squared < 0.75:
        benchmark = 'FORTE'
      else:
        benchmark = 'MUITO FORTE'
    #armazenando o resultado
      variavel.append(explicativa)
      tecnica.append('R²')
      valor.append(r_squared)
      classificacao.append(benchmark)
  #Printando o ranking
  df_ranking = pd.DataFrame({'Posição':'' ,
                            'Variável': variavel,
                             'Valor': valor,
                             'Classificação': classificacao,
                             'Técnica': tecnica})
  ordem = {'MUITO FORTE': 1, 'FORTE': 2, 'MÉDIO': 3, 'FRACO': 4, 'MUITO FRACO': 5}
  df_ranking['Posição'] = df_ranking['Classificação'].map(ordem)
  df_ranking = df_ranking.sort_values(by=['Posição','Valor'], ascending=[True, False])
  df_ranking.drop(columns=['Posição'], inplace=True)
  df_ranking.reset_index(inplace=True, drop=True)
  return df_ranking

#FUNÇÃO PARA REALIZAR ANÁLISE COMBINATÓRIA
def combinatoria(elementos, posicoes, ordem_importa, tem_repeticao):
  """Função para calcular a análise combinatória, sendo permutação, arranjo ou combinação.
  É útil para utilizar na probabilidade clássica.
  argumento1 > número de elementos possíveis(int).
  argumento2 > número de posições(int).
  argumento3 > indica se a ordem das disposições importa('sim'/'nao').
  argumento4 > indica se pode haver repetição dos elementos('sim'/'nao')."""
  if tem_repeticao == 'nao':
    if ordem_importa != "sim": #combinação sem repetição
      resultado = math.factorial(elementos) / (math.factorial(posicoes) * math.factorial(elementos - posicoes))
      print(f'O resultado é {int(resultado)} combinações possíveis.')
    elif elementos == posicoes: #permutação sem repetição
      resultado = math.factorial(elementos)
      print(f'O resultado é {int(resultado)} permutações possíveis.')
    else: #arranjo sem repetição
      resultado = math.factorial(elementos) / math.factorial(elementos - posicoes)
      print(f'O resultado é {int(resultado)} arranjos possíveis.')
  else:
    if ordem_importa != "sim": #combinação com repetição
      resultado = math.comb(elementos + posicoes - 1, posicoes)
      print(f'O resultado é {int(resultado)} combinações possíveis, com repetição.')
    elif elementos == posicoes: #permutação com repetição
      resultado = elementos ** posicoes
      print(f'O resultado é {int(resultado)} permutações possíveis, com repetição.')
    else:#arranjo com repetição
      resultado = elementos ** posicoes
      print(f'O resultado é {int(resultado)} arranjos possíveis, com repetição.')

#FUNÇÃO PARA ESTIMAR A MÉDIA POPULACIONAL
def intervalo_media(amostra,confianca):
  """Essa função tem como objetivo estimar a média do parâmetro de interesse na população, 
  a partir de uma amostra.
  argumento1 > amostra(coluna do dataframe)
  argumento2 > nível de confiança(int)"""

  # Calculando média e desvio padrão da amostra
  media_amostra = np.mean(amostra)
  desvio_padrao_amostra = np.std(amostra, ddof=1)  # Usamos ddof=1 para calcular o desvio padrão da amostra, não da população
  # Tamanho da amostra
  n = len(amostra)
  # Graus de liberdade
  graus_liberdade = n - 1
  # Calculando o intervalo de confiança
  intervalo_confianca = t.interval(confianca/100, graus_liberdade, loc=media_amostra, scale=desvio_padrao_amostra/np.sqrt(n))
  print(f'''Utilizando uma amostra de tamanho {len(amostra)}, existe a probabilidade de {confianca}% de que a real média da população esteja dentro do intervalo:
{intervalo_confianca}
Para reduzir o tamanho do intervalo é necessário aumentar o tamanho da amostra, ou diminuir a confiabilidade.''')

#FUNÇÃO PARA ESTIMAR A PROPORÇÃO POPULACIONAL
def intervalo_proporcao(amostra, confianca):
    """Essa função tem como objetivo estimar a média do parâmetro de interesse na população, 
  a partir de uma amostra.
  argumento1 > amostra(coluna do dataframe).
  argumento2 > nível de confiança(int).
    """
    # Calculando a proporção na amostra
    proporcao_amostra = np.mean(amostra)
    # Tamanho da amostra
    n = len(amostra)
    # Calculando o desvio padrão da proporção na amostra
    desvio_padrao_proporcao = np.sqrt((proporcao_amostra * (1 - proporcao_amostra)) / n)
    # Calculando o intervalo de confiança usando a distribuição normal (z)
    z = norm.ppf(1 - (1 - (confianca/100)) / 2)
    limite_inferior = proporcao_amostra - z * desvio_padrao_proporcao
    limite_superior = proporcao_amostra + z * desvio_padrao_proporcao
    intervalo_confianca = (limite_inferior,limite_superior)
    #exibindo o resultado
    print(f'''Utilizando uma amostra de tamanho {len(amostra)}, existe a probabilidade de {confianca}% de que a real proporção(valor 1) da população esteja dentro do intervalo:
{intervalo_confianca}
Para reduzir o tamanho do intervalo é necessário aumentar o tamanho da amostra, ou diminuir a confiabilidade.''')

#FUNÇÃO PARA CALCULAR O TAMANHO DA AMOSTRA
def tamanho_amostra(amostra, tipo, erro_maximo, nivel_confianca):
    """Esta função tem a finalidade de calcular o tamanho da amostra para o parâmetro de média ou proporção populacional,
    de acordo com o erro e o nível de confiança desejado.
    argumento1 > amostra(coluna do dataframe)
    argumento2 > parâmetro a ser estimado('media'/'proporcao')(int).
    argumento3 > erro máximo esperado(int).
    argumento4 > nível de confiança esperado(int).
    """
    # Convertendo o nível de confiança para a escala da distribuição normal padrão
    nivel_confianca = nivel_confianca / 100.0
    # Calculando o valor crítico da distribuição normal padrão para o nível de confiança desejado
    valor_critico = norm.ppf((1 + nivel_confianca) / 2)
    if tipo == 'media':
        # Calculando a variância amostral
        variancia_amostral = np.var(amostra, ddof=1)
        # Calculando o tamanho da amostra para média
        tamanho_amostra = ((valor_critico**2) * variancia_amostral) / (erro_maximo**2)
    elif tipo == 'proporcao':
        # Passando erro para float
        erro_maximo = erro_maximo/100
        # Calculando a proporção amostral
        p = amostra.mean()
        # Calculando o tamanho da amostra para proporção
        tamanho_amostra = ((valor_critico**2) * p * (1 - p)) / (erro_maximo**2)
    # Exibindo o resultado
    print(f'''O tamanho da amostra para se obter um erro de no máximo {erro_maximo} para mais ou para menos, considerando um nível de confiança de {int(nivel_confianca*100)}% é: 
{int(np.ceil(tamanho_amostra))}''')

#FUNÇÃO PARA REALIZAR UM TESTE DE HIPÓTESE PARA MÉDIA DE UMA AMOSTRA
def teste_media(amostra, h0, h1, nivel_significancia=0.05):
    """Esta função compara a média de uma amostra em relação à média da população.
    Exemplo: Comparação da média do Ph da água de uma represa e um valor de referência(h0). 
    - argumento1 > amostra(coluna dataframe)
    - argumento2 > valor da hipótese nula(float)
    - argumento3 > hipótese alternativa (string)("<", ">", "!=")
    - argumento4 > nível de significância para o teste (default: 0.05 escala de Fisher)
    """
    # Excluindo valores nulos das amostras(do contrário dá erro)
    amostra = amostra[~np.isnan(amostra)]
    # Plotar histograma da amostra
    num_bins = 1 + int(math.log2(len(amostra))) # Calculando o número de bins usando a regra de Sturges
    plt.figure(figsize=(3, 3))
    plt.hist(amostra, bins=num_bins, edgecolor='black')
    plt.title('Histograma da Amostra')
    plt.xlabel(amostra.name)
    plt.ylabel('Frequência')
    plt.show()
    # Atribuindo as variáveis para o cálculo
    n = len(amostra)
    media = np.mean(amostra)
    desvio = np.std(amostra, ddof=1)  # Utilizamos ddof=1 para calcular o desvio padrão amostral
    # Calculando a estatística do teste t
    estatistica_t = ((n ** 0.5) * (media - h0)) / desvio
    # Calculando o p-valor de acordo com a hipótese alternativa
    if '>' in h1:
        p_valor = 1 - t.cdf(estatistica_t, n - 1)
    elif "!=" in h1:
        p_valor = 2 * (1 - t.cdf(abs(estatistica_t), n - 1))
    else:
        p_valor = t.cdf(estatistica_t, n - 1)
    # Classificando o p-valor de acordo com a escala de fisher
    print('')
    print(f'Hipótese nula: A média da pupulação é igual a {h0}.')
    print(f'Hipótese alternativa: A média da pupulação é {"menor" if h1 == "<" else ("maior" if h1 == ">" else "diferente")} que {h0}.')
    print('-'*15)
    if p_valor > nivel_significancia:
        print(f'Não existem evidências estatísticas suficientes contra h0, ou seja, não rejeitamos h0:\np-valor = {p_valor:.2f}')
    else:
        print(f'Existem evidências estatísticas suficientes contra h0, portanto rejeitamos h0.\np-valor = {p_valor:.2f}')

#FUNÇÃO PARA REALIZAR UM TESTE DE HIPÓTESE PARA PROPORÇÃO DE UMA AMOSTRA
def teste_proporcao(amostra, p0, h1, nivel_significancia=0.05):
    """Esta função compara a proporção de uma amostra em relação à proporção da população.
    Exemplo: Comparação da proporção de clientes que compraram um produto em relação a uma proporção de referência(p0). 
    - argumento1 > amostra(coluna dataframe)
    - argumento2 > valor da proporção da hipótese nula(float)
    - argumento3 > hipótese alternativa (string)("<", ">", "!=")
    - argumento4 > nível de significância para o teste (default: 0.05 escala de Fisher)
    """
    # Excluindo valores nulos das amostras(do contrário dá erro)
    amostra = amostra[~np.isnan(amostra)]
    # Atribuindo as variáveis para o cálculo
    n = len(amostra)
    k = sum(amostra)
    # Calculando a estatística do teste z
    p_hat = k / n
    z_stat = (p_hat - p0) / (np.sqrt((p0 * (1 - p0)) / n))
    # Calculando o p-valor de acordo com a hipótese alternativa
    if h1 == '>':
        p_valor = 1 - binom.cdf(k-1, n, p0)
    elif h1 == '<':
        p_valor = binom.cdf(k, n, p0)
    else:
        p_valor = 2 * min(binom.cdf(k, n, p0), 1 - binom.cdf(k-1, n, p0))
    # Plotando gráficos de pizza
    plt.figure(figsize=(6, 3))
    plt.subplot(1, 2, 1)
    plt.pie([k, n - k], labels=['Evento', 'Não Evento'], autopct='%1.1f%%', startangle=140)
    plt.title('Amostra')
    plt.subplot(1, 2, 2)
    plt.pie([p0 * n, (1 - p0) * n], labels=['Evento', 'Não Evento'], autopct='%1.1f%%', startangle=140)
    plt.title('População')
    plt.tight_layout()
    plt.show()
    # Classificando o p-valor de acordo com o nível de significância
    print('')
    print(f'Hipótese nula: A proporção da população é igual a {p0}.')
    print(f'Hipótese alternativa: A proporção da população é {"menor" if h1 == "<" else ("maior" if h1 == ">" else "diferente")} que {p0}.')
    print('-'*15)
    if p_valor > nivel_significancia:
        print(f'Não existem evidências estatísticas suficientes contra H0, ou seja, não rejeitamos H0:\np-valor = {p_valor:.2f}')
    else:
        print(f'Existem evidências estatísticas suficientes contra H0, portanto rejeitamos H0.\np-valor = {p_valor:.2f}')

#FUNÇÃO PARA REALIZAR UM TESTE DE HIPÓTESE PARA AS MÉDIAS DE DUAS AMOSTRAS INDEPENDENTES
def teste_media_independentes(amostra1, amostra2, h1, nivel_significancia=0.05):
    """Esta função compara as médias de duas amostras independentes, em relação às suas pupulações.
    Exemplo: Comparação entre a média do Ph da água de duas represas. 
    - argumento1 > amostra 1 (array ou lista)
    - argumento2 > amostra 2 (array ou lista)
    - argumento3 > hipótese alternativa (string) ("<", ">", "!=")
    - argumento4 > nível de significância para o teste (default: 0.05)
    """
    # Nesse caso h0 será igual a zero
    h0 = 0
    # Excluindo valores nulos das amostras(do contrário dá erro)
    amostra1 = amostra1[~np.isnan(amostra1)]
    amostra2 = amostra2[~np.isnan(amostra2)]
    # Plotando histogramas
    num_bins1 = 1 + int(math.log2(len(amostra1))) # Calculando o número de bins usando a regra de Sturges
    num_bins2 = 1 + int(math.log2(len(amostra2))) # Calculando o número de bins usando a regra de Sturges
    plt.figure(figsize=(6, 3))
    plt.subplot(1, 2, 1)
    plt.hist(amostra1, bins=num_bins1, edgecolor='black')
    plt.title('Amostra 1')
    plt.xlabel(amostra1.name)
    plt.ylabel('Frequência')    
    plt.subplot(1, 2, 2)
    plt.hist(amostra2, bins=num_bins2, edgecolor='black')
    plt.title('Amostra 2')
    plt.xlabel(amostra2.name)
    plt.ylabel('Frequência') 
    plt.tight_layout()
    plt.show()
    # Alterando a hipótese alternativa para se adequar á função ttest_ind
    if h1 == '<':
      valor = 'less'
    elif h1 == '>':
      valor = 'greater'
    else:
      valor = 'two-sided'
    # Verificar se as variâncias são iguais ou diferentes
    t_valor, p_value_b = bartlett(amostra1, amostra2)
    print('')
    if p_value_b > nivel_significancia:
      print("As variâncias são iguais. Portanto, foi utilizado o teste T-padrão.")
      equal_var = True
    else:
      print("As variâncias são diferentes. Portanto, foi utilizado o Welch's T-test.")
      equal_var = False     
    # Realizar o teste t de acordo com as variâncias
    if equal_var:
        # Variâncias iguais, usar o teste t de Student padrão
        t_stat, p_valor = ttest_ind(amostra1, amostra2, equal_var=True, alternative=valor)
    else:
        # Variâncias diferentes, usar o Welch's t-test
        t_stat, p_valor = ttest_ind(amostra1, amostra2, equal_var=False, alternative=valor)  
    # Classificando o p-valor de acordo com a escala de fisher
    print('-'*15)
    if p_valor > nivel_significancia:
      print(f'''Não existem evidências estatísticas suficientes contra h0, ou seja, não rejeitamos h0.
Portanto, as médias das duas populações são iguais.  
p-valor = {p_valor:.2f}''')
    else:
      print(f'''Existem evidências estatísticas suficientes contra h0(médias iguais), ou seja, rejeitamos h0.
Portanto, a média da primeira pupulação é {"menor" if valor == 'less' else ("maior" if valor == 'greater' else "diferente")} que a segunda.
p-valor = {p_valor:.2f}''')

#FUNÇÃO PARA REALIZAR UM TESTE DE HIPÓTESE PARA MÉDIA DE DUAS AMOSTRAS PAREADAS
def teste_media_pareadas(amostra1, amostra2, h1, nivel_significancia=0.05):
    """Esta função compara as médias de duas amostras pareadas, em relação à população.
    Exemplo: comparação da média do desempenho dos mesmos funcionários, antes e após implementar um novo processo.
    - argumento1 > amostra 1 (array ou lista)
    - argumento2 > amostra 2 (array ou lista)
    - argumento3 > hipótese alternativa (string) ("<", ">", "!=")
    - argumento4 > nível de significância para o teste (default: 0.05)
    """
    # Nesse caso h0 será igual a zero
    h0 = 0
    # Excluindo valores nulos das amostras(do contrário dá erro)
    amostra1 = amostra1[~np.isnan(amostra1)]
    amostra2 = amostra2[~np.isnan(amostra2)]
     # Plotando histogramas
    num_bins1 = 1 + int(math.log2(len(amostra1))) # Calculando o número de bins usando a regra de Sturges
    num_bins2 = 1 + int(math.log2(len(amostra2))) # Calculando o número de bins usando a regra de Sturges
    plt.figure(figsize=(6, 3))
    plt.subplot(1, 2, 1)
    plt.hist(amostra1, bins=num_bins1, edgecolor='black')
    plt.title('Amostra 1')
    plt.xlabel(amostra1.name)
    plt.ylabel('Frequência')    
    plt.subplot(1, 2, 2)
    plt.hist(amostra2, bins=num_bins2, edgecolor='black')
    plt.title('Amostra 2')
    plt.xlabel(amostra2.name)
    plt.ylabel('Frequência') 
    plt.tight_layout()
    plt.show()
    # Alterando a hipótese alternativa para se adequar á função ttest_rel
    if h1 == '<':
      valor = 'less'
    elif h1 == '>':
      valor = 'greater'
    else:
      valor = 'two-sided'
    # Aplicando o teste t para populações pareadas
    t_stat, p_valor = ttest_rel(amostra1, amostra2, alternative=valor)
    # Classificando o p-valor de acordo com a escala de fisher
    print('')
    if p_valor > nivel_significancia:
      print(f'''Não existem evidências estatísticas suficientes contra h0, ou seja, não rejeitamos h0.
Portanto, as médias das duas populações pareadas são iguais.  
p-valor = {p_valor:.2f}''')
    else:
      print(f'''Existem evidências estatísticas suficientes contra h0(médias iguais), ou seja, rejeitamos h0.
Portanto, a média da primeira pupulação é {"menor" if valor == 'less' else ("maior" if valor == 'greater' else "diferente")} que a segunda.
p-valor = {p_valor:.2f}''')

#FUNÇÃO PARA REALIZAR UM TESTE DE HIPÓTESE PARA PROPORÇÃO DE DUAS AMOSTRAS INDEPENDENTES
def teste_proporcao_independentes(amostra1, amostra2, h1, nivel_significancia=0.05):
    """Esta função compara as proporções de duas amostras independentes, em relação às suas populações.
    Exemplo: Comparação entre a proporção de clientes que compraram em duas lojas diferentes. 
    - argumento1 > amostra 1 (array ou lista)
    - argumento2 > amostra 2 (array ou lista)
    - argumento3 > hipótese alternativa (string) ("<", ">", "!=")
    - argumento4 > nível de significância para o teste (default: 0.05)
    """
    # Nesse caso h0 será igual a zero
    h0 = 0
    # Excluindo valores nulos das amostras (do contrário dá erro)
    amostra1 = amostra1[~np.isnan(amostra1)]
    amostra2 = amostra2[~np.isnan(amostra2)]
    # Realizar o teste de proporções
    count1 = sum(amostra1)
    nobs1 = len(amostra1)
    count2 = sum(amostra2)
    nobs2 = len(amostra2)
    if h1 == '<':
        alternative = 'smaller'
    elif h1 == '>':
        alternative = 'larger'
    else:
        alternative = 'two-sided'
    z_stat, p_valor = proportions_ztest([count1, count2], [nobs1, nobs2], alternative=alternative)
    # Plotando gráficos de pizza
    plt.figure(figsize=(6, 3))
    plt.subplot(1, 2, 1)
    plt.pie([count1, nobs1 - count1], labels=['Evento', 'Não Evento'], autopct='%1.1f%%', startangle=140)
    plt.title('Amostra 1')
    plt.subplot(1, 2, 2)
    plt.pie([count2, nobs2 - count2], labels=['Evento', 'Não Evento'], autopct='%1.1f%%', startangle=140)
    plt.title('Amostra 2')
    plt.tight_layout()
    plt.show()
    # Classificando o p-valor de acordo com o nível de significância
    print('-'*15)
    if p_valor > nivel_significancia:
        print(f'''Não existem evidências estatísticas suficientes contra H0, ou seja, não rejeitamos H0.
Portanto, as proporções das duas populações são iguais.  
p-valor = {p_valor:.2f}''')
    else:
        print(f'''Existem evidências estatísticas suficientes contra H0 (proporções iguais), ou seja, rejeitamos H0.
Portanto, a proporção da primeira população é {"menor" if alternative == 'smaller' else ("maior" if alternative == 'larger' else "diferente")} que a segunda.
p-valor = {p_valor:.2f}''')
